{"nbformat_minor": 0, "cells": [{"execution_count": null, "cell_type": "code", "source": "import numpy as np\nfrom sklearn import linear_model\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\n#Load and parse the data \nsparkHome = os.environ.get('SPARK_HOME')\nfileLocation = sparkHome + \"/Assignment1/winequality-white.csv\";\nf = open(fileLocation);\nf.readline();\ndata = np.loadtxt(fname=f,delimiter = ';');\nX = data[:,0:10];\nY = data[:,11];\n\n#Split training/test sets\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.40);\n\n#Scaling features \nscaler = preprocessing.StandardScaler().fit(X_train);\nX_train = scaler.transform(X_train);\nX_test = scaler.transform(X_test);\n\n#Algorithm being used\nregr = linear_model.SGDRegressor (penalty='l2',n_iter=100)\n\n\n#Training the model\nregr.fit(X_train, Y_train);\n\nprint regr.coef_\nprint regr.intercept_\n\n#Predicting and printing out sqrt of mean of sum of squares and Variance\nprint(\"Residual sum of squares: %.2f\"\n      % np.sqrt(np.mean((regr.predict(X_test) - Y_test) ** 2)))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % regr.score(X_test, Y_test))", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.9", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}