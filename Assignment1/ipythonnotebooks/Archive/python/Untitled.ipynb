{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.0343766033864\n",
      "Accuracy = 0.965623396614\n"
     ]
    }
   ],
   "source": [
    "# Library Imports\n",
    "\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.mllib.feature import StandardScaler\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "# Load and parse the data\n",
    "\n",
    "def parsePoint(line):\n",
    "\n",
    "    values = [float(x) for x in line.split(',')]\n",
    "\n",
    "    return LabeledPoint(values[11], values[0:10])\n",
    "\n",
    "sc = SparkContext(\"local\", \"SVMWithSGD\")\n",
    "\n",
    "sparkHome = os.environ.get('SPARK_HOME')\n",
    "fileLocation = sparkHome + \"/Assignment1/data.csv\";\n",
    "\n",
    "data = sc.textFile(fileLocation)\n",
    "\n",
    "parsedData = data.map(parsePoint)\n",
    "\n",
    "#Split training/test sets\n",
    "\n",
    "(trainingData, testData) = parsedData.randomSplit([0.6, 0.4])\n",
    "\n",
    "#Scaling features \n",
    "\n",
    "label = trainingData.map(lambda x: x.label)\n",
    "\n",
    "features = trainingData.map(lambda x: x.features)\n",
    "\n",
    "scaler1 = StandardScaler().fit(features)\n",
    "\n",
    "trainingData = label.zip(scaler1.transform(features))\n",
    "\n",
    "trainingData = trainingData.map(lambda (x,y) : LabeledPoint(x,y))\n",
    "\n",
    "# Build the model with the parsedData for 100 iterations using regularization \n",
    "\n",
    "#parameter as 0.01 and regularization type as ‘l2’\n",
    "\n",
    "model = LogisticRegressionWithSGD.train(trainingData, \n",
    "\n",
    "iterations=100,regParam=0.01,regType='l2')\n",
    "\n",
    "# Evaluate the model on training data\n",
    "\n",
    "labelsAndPreds = testData.map(lambda p: (p.label, model.predict(p.features)))\n",
    "\n",
    "#Calculating the Training error using the following formula\n",
    "\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(testData.count())\n",
    "\n",
    "#Calculating the Accuracy using the following formula\n",
    "\n",
    "accuracy = labelsAndPreds.filter(lambda (v, p): v == p).count() / float(testData.count())\n",
    "\n",
    "#Print the Training Error and Accuracy calculated\n",
    "\n",
    "print(\"Training Error = \" + str(trainErr))\n",
    "\n",
    "print(\"Accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
