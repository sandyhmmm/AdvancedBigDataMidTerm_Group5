{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf210
{\fonttbl\f0\fnil\fcharset0 Cambria;\f1\ftech\fcharset77 Symbol;\f2\fmodern\fcharset0 CourierNewPSMT;
\f3\froman\fcharset0 TimesNewRomanPSMT;}
{\colortbl;\red255\green255\blue255;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid102\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid2}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\ri720

\f0\fs24 \cf0 Kafka-Wordcount:\
\
\pard\pardeftab720\li720\fi-360\ri720
\ls1\ilvl0
\f1 \cf0 \'a5	
\f0 Create an EMR cluster of version 3.8.0, with spark 1.3.1 installed. \
\pard\pardeftab720\li1440\fi-360\ri720
\ls1\ilvl1
\f2 \cf0 o	
\f0 Alternatively you can create EMR 4.0 version, download Spark 1.4.1 and install using maven(We faced issues with Kafka utils in pre-installed Spark 1.4.1 with EMR 4.0)\
\pard\pardeftab720\ri720

\f3 \cf0 \
\pard\pardeftab720\li720\fi-360\ri720
\ls2\ilvl1
\f1 \cf0 \'a5	
\f0 ssh into the EMR instance from terminal\
\ls2\ilvl1
\f1 \'a5	
\f0 Following commands to launch the Kafka producer\
\pard\pardeftab720\li1440\fi-360\ri720
\ls2\ilvl1
\f2 \cf0 o	
\f0 wget\'a0{\field{\*\fldinst{HYPERLINK "http://supergsego.com/apache/kafka/0.8.2.1/kafka_2.9.1-0.8.2.1.tgz%22%20%5Ct%20%22_blank"}}{\fldrslt http://supergsego.com/apache/kafka/0.8.2.1/kafka_2.9.1-0.8.2.1.tgz}}
\f3 \
\ls2\ilvl1
\f2 o	
\f0 tar \'96xvf kafka_2.9.1-0.8.2.1.tgz
\f3 \
\ls2\ilvl1
\f2 o	
\f0 cd kafka_2.9.1-0.8.2.1
\f3 \
\ls2\ilvl1
\f2 o	
\f0 ./bin/zookeeper-server-start.sh config/zookeeper.properties(to be run in separate terminals)
\f3 \
\ls2\ilvl1
\f2 o	
\f0 ./bin/kakfa-server-start.sh config/server.properties(to be run in separate terminals)
\f3 \
\ls2\ilvl1
\f2 o	
\f0 bin/kafka-topic.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic kafkatopic(to be run in separate terminals)
\f3 \
\ls2\ilvl1
\f2 o	
\f0 ./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic kafkatopic\
\ls2\ilvl1
\f2 o	
\f0 ./bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic kafkatopic --from-beginning(to be run in separate terminals)\
\pard\pardeftab720\li720\fi-360\ri720
\ls2\ilvl1
\f1 \cf0 \'a5	
\f0 Navigate to the spark home directory and run the following commands to produce the words and count them (to be run in separate terminals)\
\pard\pardeftab720\li1440\fi-360\ri720
\ls2\ilvl1
\f2 \cf0 o	
\f0 ./ bin/run-example org.apache.spark.examples.streaming.KafkaWordCountProducer localhost:9092 kafkatopic 10 5 \
\ls2\ilvl1
\f2 o	
\f0 bin/run-example org.apache.spark.examples.streaming.KafkaWordCount localhost:2181 myconsumergroup kafkatopic 1\
}